{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ДИСКЛЕЙМЕР:**\n",
    "\n",
    "Основная часть проекта выполнена без BERT. Но мне было важно с ним разобраться, поэтому после основного проекта я сделала мини версию с BERT (без подбора гиперпараметров и только логисическая регрессия, так как если больше моделй - у меня падает kernell) на обрезанном датасете (до 1000 записей)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Общее-впечатление\" data-toc-modified-id=\"Общее-впечатление-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление</font></a></span></li><li><span><a href=\"#Общее-впечатление-(ревью-2)\" data-toc-modified-id=\"Общее-впечатление-(ревью-2)-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span><font color=\"orange\">Общее впечатление (ревью 2)</font></a></span></li></ul></li><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Выбор-лучшей-модели-+-тестирование\" data-toc-modified-id=\"Выбор-лучшей-модели-+-тестирование-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Выбор лучшей модели + тестирование</a></span></li><li><span><a href=\"#Проверка-на-тестовой-выборке\" data-toc-modified-id=\"Проверка-на-тестовой-выборке-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Проверка на тестовой выборке</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Обучение</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-12 17:11:18.958637: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import warnings \n",
    "\n",
    "from scipy import stats as st\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore') # отключаем предупреждения\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import torch\n",
    "import transformers \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV\n",
    "\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, mean_squared_error, confusion_matrix, f1_score, roc_curve, roc_auc_score,r2_score,mean_absolute_error\n",
    "\n",
    "from sklearn.preprocessing import OrdinalEncoder,StandardScaler,OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline,Pipeline\n",
    "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
    "\n",
    "from tqdm import tqdm, notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.utils import shuffle\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "toxic         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликтатов как во всем датасете так и в столбце с текстами нет. Так же пропуски в данных отсуствуют."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['toxic'].value_counts().plot(kind='pie',title='Соотношение классов целевой переменной');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же мы ожем наблюдать заметный дисбаланс классов. Далее будем с ним работать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим функции для очищения текста от ненужных символов и лемматизации\n",
    "def lemmatize(text):\n",
    "    #так как тексты с которыми работаем англоязычные подбираем функцию лемматизации поддерживающую английкий язык\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    lemm_list =[wnl.lemmatize(x,pos='v') for x in text.split()]\n",
    "    lemm_text = \" \".join(lemm_list)\n",
    "        \n",
    "    return lemm_text\n",
    "\n",
    "\n",
    "def clear_text(text):\n",
    "    t=re.sub(r\"[^a-zA-z']\", ' ', text)\n",
    "    t=\" \".join(t.split())\n",
    "    return t.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['clear_text']= data['text'].apply(lambda x: clear_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lemm_text']=data['clear_text'].apply(lambda x: lemmatize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "      <th>lemm_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>explanation why the edit make under my usernam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>d'aww he matches this background colour i'm se...</td>\n",
       "      <td>d'aww he match this background colour i'm seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man i'm really not trying to edit war it's...</td>\n",
       "      <td>hey man i'm really not try to edit war it's ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>more i can't make any real suggestions on impr...</td>\n",
       "      <td>more i can't make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic  \\\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1           1  D'aww! He matches this background colour I'm s...      0   \n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4           4  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "                                          clear_text  \\\n",
       "0  explanation why the edits made under my userna...   \n",
       "1  d'aww he matches this background colour i'm se...   \n",
       "2  hey man i'm really not trying to edit war it's...   \n",
       "3  more i can't make any real suggestions on impr...   \n",
       "4  you sir are my hero any chance you remember wh...   \n",
       "\n",
       "                                           lemm_text  \n",
       "0  explanation why the edit make under my usernam...  \n",
       "1  d'aww he match this background colour i'm seem...  \n",
       "2  hey man i'm really not try to edit war it's ju...  \n",
       "3  more i can't make any real suggestions on impr...  \n",
       "4  you sir be my hero any chance you remember wha...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для верного формирования мешков слов и в последствии получения векторов разделим датасет на обучающую и тестовую  и валидационную выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_valid ,test = train_test_split(data, test_size=0.2, random_state=12345,stratify=data['toxic'])\n",
    "train, valid  = train_test_split(train_valid, test_size=0.25, random_state=12345,stratify=train_valid['toxic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train['toxic']\n",
    "valid_target = valid['toxic']\n",
    "test_target = test['toxic']\n",
    "train_valid_target = train_valid['toxic']\n",
    "\n",
    "train_features = train['lemm_text']\n",
    "valid_features = valid['lemm_text']\n",
    "test_features = test['lemm_text']\n",
    "train_valid_features = train_valid['lemm_text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Борьба с дисбалансом***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#посчитаем коффициент дисбаланса\n",
    "disbalanse_coef = int(sum(train_target==0)/ sum(train_target==1))\n",
    "disbalanse_coef_frac = round(sum(train_target==1)/ sum(train_target==0),2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#зададим функцию апсемплинга и даунсемплинга\n",
    "def upsample(features, target, repeat): \n",
    "    features_zeros = features[target == 0] \n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0] \n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat) \n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(\\\n",
    "                            features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0] \n",
    "    features_ones = features[target == 1] \n",
    "    target_zeros = target[target == 0] \n",
    "    target_ones = target[target == 1]\n",
    "    \n",
    "    features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=12345)] + [features_ones])\n",
    "    target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=12345)] + [target_ones])\n",
    "    features_downsampled, target_downsampled = shuffle(features_downsampled, target_downsampled, random_state=12345)\n",
    "    \n",
    "    return features_downsampled, target_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features_up,train_target_up = upsample(train_features,train_target,disbalanse_coef)\n",
    "#train_features_down,train_target_down = downsample(train_features,train_target,disbalanse_coef_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_up=train_features_up.values\n",
    "#corpus_train_down=train_features_down.values\n",
    "corpus_train=train_features.values\n",
    "\n",
    "corpus_valid=valid_features.values\n",
    "\n",
    "corpus_test=test_features.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/makkate/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cоставим векторы только отдельных слов (со словосочетаниями при кол-ве features dв 3500  качество моделей падает, а увеличить число не могу так как не хватает оперативной памяти)\n",
    "\n",
    "используем TfidfVectorizer вместо count_vectorzer, так как перед нами стоит задача определения тональности теста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=3500,\n",
       "                stop_words=[&#x27;be&#x27;, &#x27;from&#x27;, &#x27;any&#x27;, &#x27;ll&#x27;, &#x27;through&#x27;, &#x27;ve&#x27;,\n",
       "                            &#x27;yourself&#x27;, &#x27;haven&#x27;, &#x27;been&#x27;, &#x27;between&#x27;, &#x27;below&#x27;,\n",
       "                            &#x27;i&#x27;, &#x27;as&#x27;, &#x27;during&#x27;, &#x27;in&#x27;, &#x27;now&#x27;, &#x27;and&#x27;, &#x27;o&#x27;,\n",
       "                            &#x27;which&#x27;, &#x27;if&#x27;, &#x27;she&#x27;, &#x27;themselves&#x27;, &quot;you&#x27;ll&quot;, &#x27;we&#x27;,\n",
       "                            &#x27;her&#x27;, &quot;shan&#x27;t&quot;, &quot;won&#x27;t&quot;, &#x27;there&#x27;, &#x27;some&#x27;, &#x27;no&#x27;, ...])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=3500,\n",
       "                stop_words=[&#x27;be&#x27;, &#x27;from&#x27;, &#x27;any&#x27;, &#x27;ll&#x27;, &#x27;through&#x27;, &#x27;ve&#x27;,\n",
       "                            &#x27;yourself&#x27;, &#x27;haven&#x27;, &#x27;been&#x27;, &#x27;between&#x27;, &#x27;below&#x27;,\n",
       "                            &#x27;i&#x27;, &#x27;as&#x27;, &#x27;during&#x27;, &#x27;in&#x27;, &#x27;now&#x27;, &#x27;and&#x27;, &#x27;o&#x27;,\n",
       "                            &#x27;which&#x27;, &#x27;if&#x27;, &#x27;she&#x27;, &#x27;themselves&#x27;, &quot;you&#x27;ll&quot;, &#x27;we&#x27;,\n",
       "                            &#x27;her&#x27;, &quot;shan&#x27;t&quot;, &quot;won&#x27;t&quot;, &#x27;there&#x27;, &#x27;some&#x27;, &#x27;no&#x27;, ...])</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=3500,\n",
       "                stop_words=['be', 'from', 'any', 'll', 'through', 've',\n",
       "                            'yourself', 'haven', 'been', 'between', 'below',\n",
       "                            'i', 'as', 'during', 'in', 'now', 'and', 'o',\n",
       "                            'which', 'if', 'she', 'themselves', \"you'll\", 'we',\n",
       "                            'her', \"shan't\", \"won't\", 'there', 'some', 'no', ...])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "count_tf_idf = TfidfVectorizer(stop_words=list(stopwords),ngram_range=(1,1),max_features=3500)\n",
    "count_tf_idf.fit(corpus_train_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем векторы для обучающей и валидационных выборок."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_train_up=count_tf_idf.transform(corpus_train_up)\n",
    "tf_idf_valid = count_tf_idf.transform(corpus_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем векторы тестовой выбороки для проверки итоговой модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_test = count_tf_idf.transform(corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31859, 3500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии составила 0.7179621162638798\n"
     ]
    }
   ],
   "source": [
    "model.fit(tf_idf_train_up,train_target_up)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_logistic = f1_score(valid_target,predict)\n",
    "print(f'''f1 для логистической регрессии составила {f1_logistic}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_log=\"-\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***RandomForest***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(random_state=12345,n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для Случайного леса составила 0.7415503615268203\n",
      "CPU times: user 17min 49s, sys: 9.19 s, total: 17min 58s\n",
      "Wall time: 5min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit(tf_idf_train_up,train_target_up)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_RF = f1_score(valid_target,predict)\n",
    "print(f'''f1 для Случайного леса составила {f1_RF}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=6, n_estimators=70, random_state=12345)\n",
      "CPU times: user 4min 50s, sys: 3.15 s, total: 4min 53s\n",
      "Wall time: 4min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_max=-1000\n",
    "for n_est in range(70,350,70):\n",
    "    for depth in range(1,20,5):\n",
    "        model = RandomForestClassifier(random_state=12345,max_depth=depth, n_estimators = n_est)\n",
    "        model.fit(tf_idf_train_up,train_target_up)\n",
    "        predict = model.predict(tf_idf_valid)\n",
    "        f1 = f1_score(valid_target,predict)\n",
    "        if f1>f1_max:\n",
    "            f1_max=f1\n",
    "            best_model=model\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6740753603056087"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_RF='-'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tf_idf_train_up,train_target_up)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_RF = f1_score(valid_target,predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При подборе гиперпараметров для случайного леса мне не удалось улучшить f1 - модель переобучилась (о чем говорит большая глубина леса). Как итоговый варинат случайного леса предлагаю оставить настройки по-умолчанию."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CatboostClassifier***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.090818\n",
      "0:\tlearn: 0.6476694\ttotal: 1.27s\tremaining: 21m 12s\n",
      "500:\tlearn: 0.2233034\ttotal: 5m 27s\tremaining: 5m 25s\n",
      "999:\tlearn: 0.1660713\ttotal: 10m 55s\tremaining: 0us\n",
      "f1 для Случайного леса составила 0.7568498063405537\n",
      "CPU times: user 35min 8s, sys: 16.9 s, total: 35min 25s\n",
      "Wall time: 10min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = CatBoostClassifier()\n",
    "model.fit(tf_idf_train_up,train_target_up,verbose=500)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_CB = f1_score(valid_target,predict)\n",
    "print(f'''f1 для Случайного леса составила {f1_CB}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_CB=\"-\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку обучение данной модели занимает много времени, а получившийся результат метрики удовлетворяет условию - я не стану подбирать гиперпараметры."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***LightGBM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для LightGBM составила 0.7389317337903455\n",
      "CPU times: user 1min 26s, sys: 2.16 s, total: 1min 28s\n",
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = lgb.LGBMClassifier(n_jobs=-1)\n",
    "model.fit(tf_idf_train_up,train_target_up,verbose=300)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_LGB = f1_score(valid_target,predict)\n",
    "print(f'''f1 для LightGBM составила {f1_LGB}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 19min 13s, sys: 3min 37s, total: 3h 22min 51s\n",
      "Wall time: 59min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_max=-1000\n",
    "for depth in range(-1,16,3):\n",
    "    for n_est in range(70,400,50):\n",
    "        for l_rate in[0.1,0.3,0.8]:\n",
    "            model = lgb.LGBMClassifier(n_jobs=-1,\n",
    "                                       max_depth = depth, \n",
    "                                       n_estimators = n_est,\n",
    "                                       learning_rate = l_rate)\n",
    "            model.fit(tf_idf_train_up,train_target_up,verbose=300)\n",
    "            predict = model.predict(tf_idf_valid)\n",
    "            f1 = f1_score(valid_target,predict)\n",
    "            if f1>f1_max:\n",
    "                best_model=model\n",
    "                f1_max=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method LGBMModel.get_params of LGBMClassifier(learning_rate=0.3, max_depth=14, n_estimators=370)>\n",
      "0.771062271062271\n"
     ]
    }
   ],
   "source": [
    "print(best_model.get_params)\n",
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_LGB = f1_max\n",
    "params_LGB = best_model.get_params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XGBoost***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для XGBoost составила 0.7431220095693779\n",
      "CPU times: user 3min 17s, sys: 942 ms, total: 3min 18s\n",
      "Wall time: 54.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = xgb.XGBClassifier(n_jobs=-1)\n",
    "model.fit(tf_idf_train_up,train_target_up,verbose=300)\n",
    "predict = model.predict(tf_idf_valid)\n",
    "f1_XGB = f1_score(valid_target,predict)\n",
    "print(f'''f1 для XGBoost составила {f1_XGB}''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2h 34min 15s, sys: 1min 1s, total: 2h 35min 17s\n",
      "Wall time: 42min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "f1_max=-1000\n",
    "for depth in range(1,16,5):\n",
    "    for n_est in range(70,400,50):\n",
    "        \n",
    "        model = xgb.XGBClassifier(n_jobs=-1,\n",
    "                                       max_depth = depth, \n",
    "                                       n_estimators = n_est)\n",
    "        model.fit(tf_idf_train_up,train_target_up,verbose=300)\n",
    "        predict = model.predict(tf_idf_valid)            \n",
    "        f1 = f1_score(valid_target,predict)\n",
    "        if f1>f1_max: \n",
    "            best_model=model\n",
    "            f1_max=f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method XGBModel.get_params of XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=11, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=270, n_jobs=-1, num_parallel_tree=None,\n",
      "              predictor=None, random_state=None, ...)>\n",
      "0.7667741440196529\n"
     ]
    }
   ],
   "source": [
    "print(best_model.get_params)\n",
    "print(f1_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_XGB=f1_max\n",
    "params_XGB = best_model.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор лучшей модели + тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1-score</th>\n",
       "      <th>Model_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LightGBM Classifier</th>\n",
       "      <td>0.771062</td>\n",
       "      <td>&lt;bound method LGBMModel.get_params of LGBMClas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost Classifier</th>\n",
       "      <td>0.766774</td>\n",
       "      <td>&lt;bound method XGBModel.get_params of XGBClassi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoost Classifier</th>\n",
       "      <td>0.756850</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.717962</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Classifier</th>\n",
       "      <td>0.674075</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          F1-score  \\\n",
       "LightGBM Classifier       0.771062   \n",
       "XGBoost Classifier        0.766774   \n",
       "CatBoost Classifier       0.756850   \n",
       "Logistic Regression       0.717962   \n",
       "Random Forest Classifier  0.674075   \n",
       "\n",
       "                                                               Model_params  \n",
       "LightGBM Classifier       <bound method LGBMModel.get_params of LGBMClas...  \n",
       "XGBoost Classifier        <bound method XGBModel.get_params of XGBClassi...  \n",
       "CatBoost Classifier                                                       -  \n",
       "Logistic Regression                                                       -  \n",
       "Random Forest Classifier                                                  -  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models=['Logistic Regression','Random Forest Classifier','CatBoost Classifier','LightGBM Classifier','XGBoost Classifier']\n",
    "models_f1=[f1_logistic,f1_RF,f1_CB,f1_LGB,f1_XGB]\n",
    "models_params=[params_log,params_RF,params_CB,params_LGB,params_XGB]\n",
    "\n",
    "models_comparison=pd.DataFrame(list(zip(models_f1,models_params)),columns=['F1-score','Model_params'],index=models)\n",
    "\n",
    "models_comparison = models_comparison.sort_values(by='F1-score',ascending = False)\n",
    "\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1-score                                                 0.771062\n",
       "Model_params    <bound method LGBMModel.get_params of LGBMClas...\n",
       "Name: LightGBM Classifier, dtype: object"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_comparison.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проверка на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = lgb.LGBMClassifier(n_jobs=-1, max_depth = 14, n_estimators =370,learning_rate = 0.3)\n",
    "model.fit(tf_idf_train_up,train_target_up,verbose=300)\n",
    "predict = model.predict(tf_idf_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для LightGBM на тестовой составила 0.7700567571713453\n"
     ]
    }
   ],
   "source": [
    "print(f'''f1 для LightGBM на тестовой составила {f1_score(test_target,predict)}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На тесте модель показала стабильный результат, что говорит об устойчивости качества предскзаания выбранной модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В рамках данного проекта передо мной стояла задача обучения модели машинного обучения, которая могла бы помочь сервису более эффективно модерировать пользовательские описания контекта и своевременно сигнализировать о появлении токсичных пользовательских текстах в катрочках товаров.\n",
    "\n",
    "Для выполнения данной задачи мною была произведена предобработка уже размеченной базы данных: очистка текстов от служебных символов и лемматизация (приведение к начальной форме слов). Далее Передо мной стояла задача перевода имеющися текстов векторы. Для этого я выбрала способ, учитывающий не только частотность слова, но и его важность, определяемая величиной TF-IDF. \n",
    "\n",
    "Поскольку я работаю в рамках ограниченной памяти, то мне пришлось ограничить кол-во параметров для построения векторов до 3500. Однако перед тем как векторизовать данные с целью сгладить дисбаланс классов я произвела апсмплинг обучающей выборки и это помогла в дальнейшем избежать дисбаланса параметров при векторизации (векторизатор обучался так же на выборке, где токстичные и нетоксичные тексты были в равных долях, а занчит частотности токсичных/нестоксичных параметров были +- уравнены). Для обучения моделей это так же помогло повысить уровень предсказательной способности. \n",
    "\n",
    "Далее я протестировала 5 моделей на валидационной выборке (выборочно производя подбор гипермараметров модели, где это казалось оправданным). В итоге модель, показавшая лушчий f1 оказался бустинг LightGBM, с f1 равным 0.771 и 0.770 на валидационной и тестовой соотвественно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-10 11:44:00.807290: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.dummy import DummyClassifier,DummyRegressor\n",
    "from catboost import CatBoostClassifier\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "except:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(1000).reset_index(drop=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_class = ppb.DistilBertModel\n",
    "tokenizer_class = ppb.DistilBertTokenizer\n",
    "pretrained_weights = 'distilbert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1069 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    }
   ],
   "source": [
    "tokenized = data['text'].apply(\\\n",
    "            lambda x: tokenizer.encode(x, add_special_tokens=True)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized=pd.DataFrame(tokenized)\n",
    "#обрежем длинные строки\n",
    "tokenized['text'] = tokenized['text'].apply(lambda x: x[:512])\n",
    "tokenized=tokenized.loc[:,'text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=max([len(i) for i in tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_transform.weight']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "padded = np.array([i + [0]*(n - len(i)) for i in tokenized.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0880577564239502,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": 24,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 10,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "088edec23e10487caa948ce837d53ac6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm import notebook \n",
    "# преобразуем данные\n",
    "\n",
    "batch_size = 100\n",
    "embeddings = []\n",
    "\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "    batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)])\n",
    "    attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "\n",
    "    embeddings.append(batch_embeddings[0][:,0,:].numpy()) \n",
    "    \n",
    "features = np.concatenate(embeddings) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets=data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#разделим выборки на обучающую, валидационную и тестовую\n",
    "train_features, test_features, train_target, test_target = \\\n",
    "        train_test_split(features, targets, test_size=0.2,stratify=targets)\n",
    "\n",
    "train_features, valid_features, train_target, valid_target =\\\n",
    "    train_test_split(train_features, train_target, test_size=0.25,stratify=train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features=pd.DataFrame(train_features,index=train_target.index)\n",
    "valid_features=pd.DataFrame(valid_features,index=valid_target.index)\n",
    "test_features=pd.DataFrame(test_features,index=test_target.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(features, target, repeat): \n",
    "    features_zeros = features[target == 0] \n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0] \n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat) \n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(\\\n",
    "                            features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "disbalanse_coef = int(sum(train_target==0)/ sum(train_target==1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#для борьбы с дисбалансом произведу апсемплинг обучащей выборки\n",
    "train_features_up,train_target_up = upsample(pd.DataFrame(train_features), train_target, disbalanse_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Logistic Regression***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии составила 0.7391304347826088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_features_up,train_target_up)\n",
    "predict = model.predict(valid_features)\n",
    "f1_logistic = f1_score(valid_target,predict)\n",
    "print(f'''f1 для логистической регрессии составила {f1_logistic}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка на тестовой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 для логистической регрессии на тестовой выборке составила 0.6341463414634146\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345)\n",
    "\n",
    "model.fit(train_features_up,train_target_up)\n",
    "predict = model.predict(test_features)\n",
    "f1_logistic = f1_score(test_target,predict)\n",
    "print(f'''f1 для логистической регрессии на тестовой выборке составила {f1_logistic}''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
